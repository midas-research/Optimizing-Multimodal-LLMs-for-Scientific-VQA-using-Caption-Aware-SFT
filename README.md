# Enhancing Scientific Visual Question Answering via Vision-Caption aware Supervised Fine-Tuning

---

## ðŸ“˜ Overview

This work focuses on improving **Scientific Visual Question Answering (SciVQA)** by incorporating **Vision-Caption aware Supervised Fine-Tuning (VCASFT)**. This approach leverages both visual and caption information from scientific figures to enhance reasoning and answer generation.


## ðŸ§© Framework

The proposed VCASFT framework integrates caption along with visual features during fine-tuning, enriching the modelâ€™s understanding of scientific figures and textual annotations.

<p align="center"> <img src="VCASFT_Framework.png" alt="VCASFT Framework" width="700"/> </p>


## ðŸš€ Key Highlights

âœ… **HiSciVQA Dataset** - A high-quality Multimodal Hindi Physics Question Answering Dataset

âœ… **VCASFT** - A novel training paradigm that jointly leverages visual and caption information to improve reasoning in scientific VQA.

âœ… **Performance Gains** - VCASFT Demonstrates substantial gains on HiSciVQA benchmarks across reasoning and answer quality metrics.

## ðŸ“‚ HiSciVQA Dataset

### Data Files

```
data/
â”œâ”€â”€ HiSciVQA_Train_Data.json
â””â”€â”€ HiSciVQA_Test_Data.json

```
### Images

```
images/
â”œâ”€â”€ train_images.zip
â””â”€â”€ test_images.zip

```

## ðŸ“¬ Contact

For any questions or feedback, please feel free to reach out:

**Janak Kapuriya**
kapuriya22032@iiitd.ac.in


## ðŸ“‘ Citation

If you use this dataset or build upon this work, please cite:

```
@inproceedings{kapuriya2025enhancing,
  title={Enhancing Scientific Visual Question Answering via Vision-Caption aware Supervised Fine-Tuning},
  author={Kapuriya, Janak and Shaikh, Anwar and Goel, Arnav and Hira, Medha and Singh, Apoorv and Saraf, Jay and Sanjana and Nauriyal, Vaibhav and Anand, Avinash and Wang, Zhengkui and others},
  booktitle={Proceedings of the 2nd International Workshop on Large Vision-Language Model Learning and Applications},
  pages={13--30},
  year={2025}
}
```
